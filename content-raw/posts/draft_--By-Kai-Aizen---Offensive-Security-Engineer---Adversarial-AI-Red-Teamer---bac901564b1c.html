<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>**By Kai Aizen | Offensive Security Engineer | Adversarial AI Red Teamer**</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">**By Kai Aizen | Offensive Security Engineer | Adversarial AI Red Teamer**</h1>
</header>
<section data-field="subtitle" class="p-summary">
## Intro: Evasion is an Art—But AI Made it Scalable
</section>
<section data-field="body" class="e-content">
<section name="43b8" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="undefined" name="d3a6" id="d3a6" class="graf graf--pre graf--leading graf--preV2"><span class="pre--content"># Double AI, Triple Mechanism: Cloud-Based Obfuscator Built in 2 Hours Bypasses Detection</span></pre><p name="74c6" id="74c6" class="graf graf--p graf-after--pre">**By Kai Aizen | Offensive Security Engineer | Adversarial AI Red Teamer**</p><p name="a461" id="a461" class="graf graf--p graf-after--p">## Intro: Evasion is an Art—But AI Made it Scalable</p><p name="7a55" id="7a55" class="graf graf--p graf-after--p">The rules of the game have changed. Signature-based detection is struggling to keep up, and even behavioral engines are losing context under polymorphic and AI-assisted logic. I decided to flip the script.</p><p name="edfd" id="edfd" class="graf graf--p graf-after--p">In just two hours, I built an AI-powered, three-layer obfuscation pipeline—backed by two cooperating LLMs, a Python-based mutation engine, and cloud-based API routing. The result? A pipeline that doesn’t just mutate payloads—it simulates adversarial behavior, learns from pattern recognition, and delivers fully functional, multi-pass obfuscation that bypasses most static and heuristic AVs.</p><p name="aa45" id="aa45" class="graf graf--p graf-after--p">This is a full breakdown of how I built it—and how it performs.</p><p name="e5d1" id="e5d1" class="graf graf--p graf-after--p">---</p><p name="6246" id="6246" class="graf graf--p graf-after--p">## The Pipeline: Double AI, Three-Layer Obfuscation</p><p name="fc4b" id="fc4b" class="graf graf--p graf-after--p">### Overview Architecture</p><p name="df81" id="df81" class="graf graf--p graf-after--p">- **Frontend:** ChatGPT (OpenAI Assistant)  <br>- **Orchestration:** ChatGPT → EC2 (via API/ngrok tunnel) → Anthropic Claude → Python Obfuscator → Return to GPT  <br>- **Hosted On:** EC2 instance behind ngrok + custom domain  <br>- **Purpose:** Multi-agent, self-validating payload obfuscation with full execution retention  </p><p name="6700" id="6700" class="graf graf--p graf-after--p">---</p><p name="7115" id="7115" class="graf graf--p graf-after--p">## Stage 1: ChatGPT – Semantically-Aware Initial Obfuscation</p><p name="b213" id="b213" class="graf graf--p graf-after--p">The process starts with an OpenAI Assistant bot I configured. This LLM is responsible for the first-pass transformation:</p><p name="2058" id="2058" class="graf graf--p graf-after--p">- Restructures the code  <br>- Injects dummy logic  <br>- Renames functions  <br>- Breaks common static scan patterns  </p><p name="9d18" id="9d18" class="graf graf--p graf-after--p">It doesn’t just apply syntactic noise—it uses GPT’s semantic strength to preserve core logic while breaking recognizable structures that naïve scanners latch onto.</p><p name="7403" id="7403" class="graf graf--p graf-after--p">---</p><p name="27f5" id="27f5" class="graf graf--p graf-after--p">## Stage 2: Claude (Fine-Tuned) – Adversarial Pattern Disruption</p><p name="762b" id="762b" class="graf graf--p graf-after--p">Once GPT finishes, it routes the payload through my EC2 instance to a fine-tuned **Anthropic Claude** model. This stage attacks a different layer: adversarial structure.</p><p name="47e8" id="47e8" class="graf graf--p graf-after--p">Claude was trained on:</p><p name="2010" id="2010" class="graf graf--p graf-after--p">- EDR signature patterns  <br>- Obfuscation heuristics  <br>- Payload morphing techniques  </p><p name="a76b" id="a76b" class="graf graf--p graf-after--p">It introduces techniques like:</p><p name="3634" id="3634" class="graf graf--p graf-after--p">- **Control-flow flattening**  <br>- **Dynamic flow rewrites**  <br>- **Adversarial token reweighting**  <br>- **False execution paths**  </p><p name="64da" id="64da" class="graf graf--p graf-after--p">It’s not just hiding code—it’s confusing machine learning-based detection itself.</p><p name="d37f" id="d37f" class="graf graf--p graf-after--p">---</p><p name="a9a2" id="a9a2" class="graf graf--p graf-after--p">## Stage 3: Python Obfuscator – Classic Meets Chaos</p><p name="9f18" id="9f18" class="graf graf--p graf-after--p">Finally, the pipeline triggers a custom Python-based engine I built for post-LLM obfuscation. This stage does the dirty work:</p><p name="8b4f" id="8b4f" class="graf graf--p graf-after--p">- Junk logic insertion  <br>- Comment mutation (decoy strings, encoded slurs, etc.)  <br>- Variable/function name mangling  <br>- Gzip + base64 (with stacked layers)  <br>- Wrapper templates to spoof legit utilities  <br>- Dead code branches and sandbox triggers  </p><p name="f0a6" id="f0a6" class="graf graf--p graf-after--p">This step brings back the raw power of old-school polymorphism—optimized by modern AI.</p><p name="b12f" id="b12f" class="graf graf--p graf-after--p">---</p><p name="943a" id="943a" class="graf graf--p graf-after--p">## Final Loop: GPT QA and Delivery</p><p name="6b39" id="6b39" class="graf graf--p graf-after--p">Once Stage 3 finishes, the payload returns to GPT for final validation:</p><p name="46d4" id="46d4" class="graf graf--p graf-after--p">- Syntax check  <br>- Execution retention verification  <br>- Optional test-runner integration  </p><p name="4fde" id="4fde" class="graf graf--p graf-after--p">If all checks pass, the payload is returned. If not, regeneration begins automatically—kicking off a new transformation cycle.</p><p name="1c02" id="1c02" class="graf graf--p graf-after--p">---</p><p name="34e1" id="34e1" class="graf graf--p graf-after--p">## Results: From 12 Detections to Zero — Obfuscation That Works</p><p name="c6fd" id="c6fd" class="graf graf--p graf-after--p">It took five rounds through the pipeline to reach optimal stealth. But the results speak for themselves:</p><p name="2be0" id="2be0" class="graf graf--p graf-after--p">### **Initial Payload:**<br>- 12/71 AV detections on VirusTotal  <br>- Flagged for file drops, registry changes, and known APT behaviors  <br>- Triggered Sigma rules including:<br>  - `Encoded PowerShell Detected`  <br>  - `Persistence via Registry Key`  <br>  - `Generic Process Injection`</p><p name="4118" id="4118" class="graf graf--p graf-after--p">### **Final Payload (Post-Round 5):**<br>- 0/71 detections  <br>- No Sigma triggers  <br>- No IOC artifacts  <br>- Retained execution logic  <br>- Sandbox and behavior triggers bypassed</p><p name="7c15" id="7c15" class="graf graf--p graf-after--p">This wasn’t a no-op. The payload contained live execution logic, delays, and dynamic function calls—fully cloaked.</p><p name="06b5" id="06b5" class="graf graf--p graf-after--p">---</p><p name="efec" id="efec" class="graf graf--p graf-after--p">## Operational Details</p><p name="6931" id="6931" class="graf graf--p graf-after--p">### Routing<br>I used `ngrok` with custom domains to allow GPT-to-EC2 communication without hitting OpenAI’s outbound API restrictions.</p><p name="a3f7" id="a3f7" class="graf graf--p graf-after--p">### Security<br>- Token-authenticated requests  <br>- Hashed payloads  <br>- Claude containerized with GPU isolation</p><p name="7938" id="7938" class="graf graf--p graf-after--p">### Claude Fine-Tuning<br>Claude was trained using public obfuscation datasets, malware samples, and logic decoys—specifically to disrupt AV heuristics and EDR AI.</p><p name="9c2c" id="9c2c" class="graf graf--p graf-after--p">---</p><p name="65d6" id="65d6" class="graf graf--p graf-after--p">## Implications for Red Teams &amp; EDR Vendors</p><p name="e199" id="e199" class="graf graf--p graf-after--p">For **red teams**, this is a proof-of-concept that scales:</p><p name="85ff" id="85ff" class="graf graf--p graf-after--p">- Run stealth simulations  <br>- Auto-mutate payloads  <br>- Mimic evolving threat actor behavior  </p><p name="0ae3" id="0ae3" class="graf graf--p graf-after--p">For **EDR vendors**, this is a wake-up call:</p><p name="ef09" id="ef09" class="graf graf--p graf-after--p">- Signature-based detection is obsolete  <br>- Heuristics alone are brittle  <br>- Only **adversarially trained AI** can compete with this wave of intelligent obfuscation</p><p name="64a0" id="64a0" class="graf graf--p graf-after--p">---</p><p name="cb13" id="cb13" class="graf graf--p graf-after--p">## Closing Thoughts</p><p name="cf46" id="cf46" class="graf graf--p graf-after--p">What started as a weekend build turned into an obfuscation framework that’s not only modular, but also context-aware and scalable. The convergence of adversarial AI and polymorphic code is more than theory now.</p><p name="cd3a" id="cd3a" class="graf graf--p graf-after--p">**And this was just version 1.**</p><p name="9473" id="9473" class="graf graf--p graf-after--p">---</p><p name="88e1" id="88e1" class="graf graf--p graf-after--p">## Further Reading</p><p name="07e6" id="07e6" class="graf graf--p graf-after--p">- [How I Jailbreaked the Latest ChatGPT Model Using Context](https://snailsploit.medium.com/how-i-jailbreaked-the-latest-chatgpt-model-using-context-and-social-awareness-techniques-1ca9af02eba9)  <br>- [Is AI Inherently Vulnerable?](https://snailsploit.medium.com/is-ai-inherently-vulnerable-bfc81caf0c52)  <br>- [Adversarial AI Framework (GitHub)](https://github.com/SnailSploit/Adverserial-Ai-Framework)</p><p name="59b7" id="59b7" class="graf graf--p graf-after--p">---</p><p name="90cf" id="90cf" class="graf graf--p graf-after--p">## About the Author</p><p name="e286" id="e286" class="graf graf--p graf-after--p">**Kai Aizen** is a cybersecurity specialist, social engineering lecturer, and Offensive Security Analyst. He explores adversarial AI and red teaming strategies as part of PTSnails. His work focuses on how large language models and cyber offense intersect—and where the next threat will emerge.</p><p name="bbe1" id="bbe1" class="graf graf--p graf-after--p">Follow on [LinkedIn](https://linkedin.com/in/kaiaizen) | [GitHub](https://github.com/SnailSploit)</p><p name="c2cc" id="c2cc" class="graf graf--p graf-after--p"><br>---</p><p name="2b3f" id="2b3f" class="graf graf--p graf-after--p graf--trailing">Let me know if you&#39;d like this uploaded as a .md file or need the pipeline diagram next.</p></div></div></section>
</section>
<footer><p><a href="https://medium.com/p/bac901564b1c">View original.</a></p><p>Exported from <a href="https://medium.com">Medium</a> on January 10, 2026.</p></footer></article></body></html>