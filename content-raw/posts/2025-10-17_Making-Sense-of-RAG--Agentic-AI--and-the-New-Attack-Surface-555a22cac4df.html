<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Making Sense of RAG, Agentic AI, and the New Attack Surface</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Making Sense of RAG, Agentic AI, and the New Attack Surface</h1>
</header>
<section data-field="subtitle" class="p-summary">
Understanding the Foundation: From Hallucination to Full Attack Surface
</section>
<section data-field="body" class="e-content">
<section name="2666" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="0e38" id="0e38" class="graf graf--h3 graf--leading graf--title">Making Sense of RAG, Agentic AI, and the New Attack¬†Surface</h3><p name="31de" id="31de" class="graf graf--p graf-after--h3 graf--trailing">&quot;The AI landscape&quot;, (Sorry, had to start with that clich√©¬†;)<br>. has exploded with acronyms that often get thrown around interchangeably: RAG, agentic systems, multi-agent frameworks, and various permutations thereof. For offensive security practitioners, understanding these architectures isn‚Äôt just academic‚Ää‚Äî‚Ääeach design pattern introduces distinct attack surfaces that require specific exploitation strategies. Let‚Äôs cut through the hype and examine what these systems actually are, how they differ, and where the security vulnerabilities lie.</p></div></div></section><section name="5569" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="b640" id="b640" class="graf graf--h3 graf--leading">Understanding the Foundation: Next Token Prediction and Hallucination</h3><p name="b7e0" id="b7e0" class="graf graf--p graf-after--h3">Before we dive into complex architectures, we need to understand the fundamental mechanism that powers all these systems‚Ää‚Äî‚Ääand why it‚Äôs inherently problematic from a security perspective.</p><figure name="d26a" id="d26a" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ZQ8k80s8h5tkvoiM0gL3Vw.png" data-width="1404" data-height="876" src="https://cdn-images-1.medium.com/max/800/1*ZQ8k80s8h5tkvoiM0gL3Vw.png"></figure><h3 name="bff5" id="bff5" class="graf graf--h3 graf-after--figure">How LLMs Actually Work: The Next Token Prediction Machine</h3><p name="9de5" id="9de5" class="graf graf--p graf-after--h3">Large Language Models don‚Äôt actually ‚Äúunderstand‚Äù anything in the way humans do. At their core, they‚Äôre sophisticated next-token prediction engines. Given a sequence of tokens (words, parts of words, or characters), the model calculates a probability distribution over all possible next tokens and selects one.</p><p name="092e" id="092e" class="graf graf--p graf-after--p">This is the critical security insight: <strong class="markup--strong markup--p-strong">the model doesn‚Äôt retrieve facts, it generates plausible continuations</strong>. When you ask ‚ÄúWhat is the capital of France?‚Äù the model doesn‚Äôt look up the answer‚Ää‚Äî‚Ääit predicts that ‚ÄúParis‚Äù is the most likely continuation of that sequence based on patterns in its training data.</p><figure name="c9b5" id="c9b5" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*AwiBms50Z5Ca4HQe6f0roA.png" data-width="1024" data-height="1024" src="https://cdn-images-1.medium.com/max/800/1*AwiBms50Z5Ca4HQe6f0roA.png"></figure><h3 name="cb02" id="cb02" class="graf graf--h3 graf-after--figure">Why This Causes Hallucinations</h3><p name="6ba7" id="6ba7" class="graf graf--p graf-after--h3">Hallucinations occur when the model generates plausible-sounding but factually incorrect information. From a security perspective, this is catastrophic because:</p><p name="d789" id="d789" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Confidence is decoupled from accuracy.</strong> The model can generate completely fabricated information with the same linguistic confidence as true information. It might confidently state that a CVE exists when it doesn‚Äôt, cite non-existent security research, or invent API endpoints that sound plausible.</p><p name="92e8" id="92e8" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Context poisoning is multiplicative.</strong> Once a hallucination enters the context, it influences all subsequent token predictions. The model will generate content consistent with the hallucination, building an increasingly elaborate false narrative.</p><p name="6427" id="6427" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">No ground truth verification.</strong> Without external validation, there‚Äôs no mechanism to prevent hallucinations. The model‚Äôs only goal is generating likely token sequences, not accurate ones.</p><p name="900d" id="900d" class="graf graf--p graf-after--p">This is why RAG and agentic systems exist‚Ää‚Äî‚Ääthey attempt to ground the model‚Äôs outputs in retrievable facts and verifiable actions. But as we‚Äôll see, these solutions introduce their own attack surfaces.</p><figure name="3cb0" id="3cb0" class="graf graf--figure graf-after--p graf--trailing"><img class="graf-image" data-image-id="1*oIDwblTZQMpx9463KL2VNw.png" data-width="1410" data-height="990" src="https://cdn-images-1.medium.com/max/800/1*oIDwblTZQMpx9463KL2VNw.png"></figure></div></div></section><section name="25d5" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="03ef" id="03ef" class="graf graf--h3 graf--leading">RAG: Retrieval-Augmented Generation</h3><p name="2ea4" id="2ea4" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">What it means:</strong> RAG is an architectural pattern that augments large language models with external knowledge retrieval. Instead of relying solely on training data, the system retrieves relevant documents from a knowledge base before generating responses.</p><p name="2c3c" id="2c3c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">How it works:</strong></p><ol class="postList"><li name="6150" id="6150" class="graf graf--li graf-after--p">User query arrives</li><li name="fde6" id="fde6" class="graf graf--li graf-after--li">Query is embedded into a vector representation</li><li name="e6b0" id="e6b0" class="graf graf--li graf-after--li">Vector similarity search retrieves relevant documents from a vector database</li><li name="ca57" id="ca57" class="graf graf--li graf-after--li">Retrieved context is injected into the LLM prompt</li><li name="f9e0" id="f9e0" class="graf graf--li graf-after--li">LLM generates response using both its training and the retrieved context</li></ol><figure name="298e" id="298e" class="graf graf--figure graf-after--li graf--trailing"><img class="graf-image" data-image-id="1*Gq_HdARyhS4oNuf9t-desw.png" data-width="1024" data-height="1024" src="https://cdn-images-1.medium.com/max/800/1*Gq_HdARyhS4oNuf9t-desw.png"></figure></div></div></section><section name="161d" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="2483" id="2483" class="graf graf--h3 graf--leading">The Attack¬†Surface</h3><p name="ae93" id="ae93" class="graf graf--p graf-after--h3">RAG systems expose several interesting vectors. The retrieval mechanism itself can be poisoned‚Ää‚Äî‚Ääif you can inject malicious documents into the knowledge base, you control what context the LLM receives. This is particularly dangerous because the system is explicitly designed to trust and prioritize retrieved content over general knowledge.</p><p name="fbef" id="fbef" class="graf graf--p graf-after--p">Prompt injection takes on new dimensions here. You can craft queries that manipulate the retrieval process itself, potentially causing the system to fetch unintended documents. Vector search systems often use approximate nearest neighbor algorithms, which can be exploited through adversarial embedding attacks‚Ää‚Äî‚Ääcrafting inputs that retrieve entirely unrelated content.</p><p name="5d35" id="5d35" class="graf graf--p graf-after--p">The embedding models used for vectorization are also targets. These models can be attacked to produce similar embeddings for semantically different content, essentially creating collision attacks in the retrieval space. If the embedding model maps your malicious query to the same vector space as legitimate administrative queries, you‚Äôve just performed a privilege escalation at the semantic level.</p><p name="c77b" id="c77b" class="graf graf--p graf-after--p">Data exfiltration becomes more nuanced with RAG. You‚Äôre not just extracting what the model knows from training‚Ää‚Äî‚Ääyou can potentially enumerate the entire knowledge base through carefully crafted queries that reveal document structure, metadata, or even trigger the retrieval of sensitive documents that get partially exposed in responses.</p><h3 name="85fd" id="85fd" class="graf graf--h3 graf-after--p">Agentic Systems: When LLMs Take¬†Actions</h3><p name="0f2e" id="0f2e" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">What it means:</strong> An agentic system gives an LLM the ability to take actions in the world beyond just generating text. The model can call functions, use tools, make decisions, and execute multi-step workflows autonomously.</p><p name="1166" id="1166" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">How it works:</strong></p><ol class="postList"><li name="5760" id="5760" class="graf graf--li graf-after--p">LLM receives a goal or query</li><li name="3c4d" id="3c4d" class="graf graf--li graf-after--li">Model reasons about what actions are needed</li><li name="edcb" id="edcb" class="graf graf--li graf-after--li">LLM selects and calls available tools/functions</li><li name="06b5" id="06b5" class="graf graf--li graf-after--li">Results are fed back to the LLM</li><li name="9937" id="9937" class="graf graf--li graf-after--li">Process repeats until the goal is achieved</li></ol><figure name="810d" id="810d" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*17iJuteMPC-AggN24BOUOQ.png" data-width="1024" data-height="1024" src="https://cdn-images-1.medium.com/max/800/1*17iJuteMPC-AggN24BOUOQ.png"></figure><h3 name="363f" id="363f" class="graf graf--h3 graf-after--figure">Multi-Agent Systems: Complexity Multiplication</h3><p name="7661" id="7661" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">What it means:</strong> Multiple AI agents working together, each with specialized roles, communicating and coordinating to accomplish complex tasks.</p><p name="0926" id="0926" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">How it works:</strong></p><ol class="postList"><li name="15ed" id="15ed" class="graf graf--li graf-after--p">Different agents have different capabilities and knowledge domains</li><li name="cae0" id="cae0" class="graf graf--li graf-after--li">Agents communicate through structured protocols</li><li name="6ed9" id="6ed9" class="graf graf--li graf-after--li">A coordinator or orchestration layer manages agent interactions</li><li name="89ae" id="89ae" class="graf graf--li graf-after--li">Agents may negotiate, delegate, or collaborate on subtasks</li></ol><figure name="b2e2" id="b2e2" class="graf graf--figure graf-after--li graf--trailing"><img class="graf-image" data-image-id="1*jvmGQGnLLUx2nP9Iu1e0pQ.png" data-width="1024" data-height="1024" src="https://cdn-images-1.medium.com/max/800/1*jvmGQGnLLUx2nP9Iu1e0pQ.png"></figure></div></div></section><section name="ec50" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="bbb3" id="bbb3" class="graf graf--h3 graf--leading">Agentic RAG: The Hybrid¬†Approach</h3><p name="e307" id="e307" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">What it means:</strong> Systems that combine retrieval-augmented generation with agentic capabilities. The agent can decide when and how to retrieve information as part of its autonomous workflow.</p><p name="d51c" id="d51c" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">How it works:</strong></p><ol class="postList"><li name="5da5" id="5da5" class="graf graf--li graf-after--p">Agent receives a complex task</li><li name="45f3" id="45f3" class="graf graf--li graf-after--li">Agent reasons about what information it needs</li><li name="eb66" id="eb66" class="graf graf--li graf-after--li">Agent autonomously performs RAG operations to gather context</li><li name="efdf" id="efdf" class="graf graf--li graf-after--li">Agent uses retrieved information to inform further actions</li><li name="73f7" id="73f7" class="graf graf--li graf-after--li">Process continues iteratively until task completion</li></ol><figure name="2b15" id="2b15" class="graf graf--figure graf-after--li graf--trailing"><img class="graf-image" data-image-id="1*n3xB1imAtou8yWoUgHG-SQ.png" data-width="1024" data-height="1024" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*n3xB1imAtou8yWoUgHG-SQ.png"></figure></div></div></section><section name="95d0" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="3041" id="3041" class="graf graf--h3 graf--leading">The Attack¬†Surface</h3><p name="c9d3" id="c9d3" class="graf graf--p graf-after--h3">This is the most complex architecture from a security perspective because it combines and amplifies the attack surfaces of both RAG and agentic systems. The agent‚Äôs ability to autonomously decide what to retrieve creates a new class of vulnerabilities.</p><p name="573b" id="573b" class="graf graf--p graf-after--p">Retrieval manipulation becomes more dangerous when the agent controls the retrieval process. Attackers can craft inputs that cause the agent to retrieve and trust malicious documents as part of its autonomous workflow. The agent might even retrieve attack payloads that it then executes through its tool-calling capabilities.</p><p name="75c6" id="75c6" class="graf graf--p graf-after--p">Information flow attacks exploit the pipeline from retrieval through reasoning to action. Each stage provides opportunities for injection, and successful attacks at one stage can cascade through the system. You might inject through retrieved documents, manipulate the agent‚Äôs reasoning about that information, and ultimately cause malicious tool calls.</p><p name="91cd" id="91cd" class="graf graf--p graf-after--p graf--trailing">The autonomy creates a unique vulnerability‚Ää‚Äî‚Ääthe agent can be manipulated into creating its own attack chain. Rather than executing a pre-planned attack, you guide the agent into discovering and executing attack steps on its own through carefully crafted goals or constraints.</p></div></div></section><section name="ba55" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="9afb" id="9afb" class="graf graf--h3 graf--leading">Hallucination as Attack Amplifier</h3><p name="d635" id="d635" class="graf graf--p graf-after--h3">The fundamental problem with all these architectures is that they‚Äôre built on a foundation that doesn‚Äôt distinguish between truth and statistical likelihood. When an LLM hallucinates in a basic chatbot, you get misinformation. When it hallucinates in a RAG system with access to sensitive documents, you get data leaks. When it hallucinates in an agentic system with tool access, you get arbitrary code execution.</p><p name="59e3" id="59e3" class="graf graf--p graf-after--p">The hallucination problem multiplies with system capabilities:</p><ul class="postList"><li name="9d11" id="9d11" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Basic LLM</strong>: Generates false information (user might believe it)</li><li name="f487" id="f487" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">RAG system</strong>: Retrieves and amplifies false information (system explicitly trusts it)</li><li name="560e" id="560e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Agentic system</strong>: Acts on false information (system executes based on it)</li><li name="3dbc" id="3dbc" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Multi-agent system</strong>: Propagates false information across agents (entire system coordinated around it)</li></ul><p name="d65d" id="d65d" class="graf graf--p graf-after--li graf--trailing">This is why defensive strategies that work for chatbots fail catastrophically in production AI systems with elevated privileges.</p></div></div></section><section name="07fe" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="8e67" id="8e67" class="graf graf--h3 graf--leading">Common Vulnerabilities Across All Architectures</h3><p name="f5ba" id="f5ba" class="graf graf--p graf-after--h3">Certain attack patterns apply regardless of the specific architecture. Prompt injection remains fundamental‚Ää‚Äî‚Ääthe ability to override system instructions through user input affects all LLM-based systems. However, the impact varies dramatically based on what capabilities the system has access to.</p><p name="003a" id="003a" class="graf graf--p graf-after--p">Context window attacks exploit the limited context that LLMs can process. By filling the context with attacker-controlled content, you can push out important system instructions or safety guidelines. In RAG systems, this might mean overwhelming the context with retrieved documents. In agentic systems, it could mean flooding the conversation history with manipulated tool results.</p><p name="ead4" id="ead4" class="graf graf--p graf-after--p">Denial of service takes new forms in these systems. Beyond traditional resource exhaustion, you can cause semantic DoS where the system becomes unable to produce useful outputs due to corrupted reasoning, poisoned knowledge bases, or deliberately confusing agent coordination.</p><p name="32bb" id="32bb" class="graf graf--p graf-after--p">Model extraction and inference attacks allow attackers to probe system behavior to understand the underlying prompts, tool configurations, or knowledge base structure. This reconnaissance enables more sophisticated attacks tailored to the specific implementation.</p><h3 name="4725" id="4725" class="graf graf--h3 graf-after--p">Defensive Considerations</h3><p name="d453" id="d453" class="graf graf--p graf-after--h3">Understanding these architectures from an offensive perspective should inform defensive strategies. Input validation becomes more complex‚Ää‚Äî‚Ääyou‚Äôre not just validating data types but semantic intent. You need to validate not just what is being said but what the system might do with that input.</p><p name="3518" id="3518" class="graf graf--p graf-after--p">Least privilege principles apply to tool access. Agents should only have access to the minimum tools necessary for their function. Consider implementing tool access controls that are context-dependent rather than static.</p><p name="e885" id="e885" class="graf graf--p graf-after--p">Monitoring and observability become critical. You need visibility into retrieval patterns, tool call sequences, and agent reasoning chains to detect anomalous behavior. However, be aware that attackers can potentially poison these observability systems as well.</p><p name="a5e8" id="a5e8" class="graf graf--p graf-after--p">Isolation between components provides defense in depth. Keep retrieval systems, LLMs, and tool execution environments separated with proper security boundaries. Don‚Äôt assume that because everything involves ‚ÄúAI‚Äù it can all run in the same trust zone.</p><h3 name="9c08" id="9c08" class="graf graf--h3 graf-after--p">Conclusion: A Quick Reference Guide</h3><p name="66ae" id="66ae" class="graf graf--p graf-after--h3">Let me give you the TL;DR that you can reference when assessing these systems:</p><p name="e247" id="e247" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">RAG (Retrieval-Augmented Generation)</strong></p><ul class="postList"><li name="ceb0" id="ceb0" class="graf graf--li graf-after--p">What it does: Fetches documents before generating responses</li><li name="c45c" id="c45c" class="graf graf--li graf-after--li">Primary attack surface: Knowledge base and retrieval mechanism</li><li name="d85e" id="d85e" class="graf graf--li graf-after--li">Key vulnerability: Poisoned documents become trusted sources</li><li name="8dfb" id="8dfb" class="graf graf--li graf-after--li">Impact: Data exfiltration, information manipulation</li></ul><p name="b7fd" id="b7fd" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Agentic Systems</strong></p><ul class="postList"><li name="5ee0" id="5ee0" class="graf graf--li graf-after--p">What it does: LLM can call functions and take actions autonomously</li><li name="fc76" id="fc76" class="graf graf--li graf-after--li">Primary attack surface: Tool/function calling interface</li><li name="9171" id="9171" class="graf graf--li graf-after--li">Key vulnerability: Manipulating tool selection and parameters</li><li name="837a" id="837a" class="graf graf--li graf-after--li">Impact: Remote code execution, privilege escalation</li></ul><p name="a0f2" id="a0f2" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Multi-Agent Systems</strong></p><ul class="postList"><li name="abb6" id="abb6" class="graf graf--li graf-after--p">What it does: Multiple specialized agents coordinate on tasks</li><li name="00d8" id="00d8" class="graf graf--li graf-after--li">Primary attack surface: Inter-agent communication and orchestration</li><li name="31a1" id="31a1" class="graf graf--li graf-after--li">Key vulnerability: Compromising one agent spreads laterally</li><li name="4e4a" id="4e4a" class="graf graf--li graf-after--li">Impact: System-wide compromise, Byzantine faults</li></ul><p name="0b2c" id="0b2c" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Agentic RAG</strong></p><ul class="postList"><li name="d4af" id="d4af" class="graf graf--li graf-after--p">What it does: Agent autonomously retrieves information and takes actions</li><li name="ec81" id="ec81" class="graf graf--li graf-after--li">Primary attack surface: ALL OF THE ABOVE + autonomous decision-making</li><li name="4126" id="4126" class="graf graf--li graf-after--li">Key vulnerability: Agent creates its own attack chains</li><li name="b6fe" id="b6fe" class="graf graf--li graf-after--li">Impact: Cascading exploitation across retrieval and execution</li></ul><p name="a2e4" id="a2e4" class="graf graf--p graf-after--li"><strong class="markup--strong markup--p-strong">Next-Token Prediction &amp; Hallucination</strong></p><ul class="postList"><li name="10da" id="10da" class="graf graf--li graf-after--p">The fundamental issue: LLMs don‚Äôt retrieve truth, they predict likely continuations</li><li name="3234" id="3234" class="graf graf--li graf-after--li">Why it matters: Hallucinations get more dangerous with increased system capabilities</li><li name="5717" id="5717" class="graf graf--li graf-after--li graf--trailing">The multiplier effect: Basic LLM = lies, RAG = trusted lies, Agentic = executed lies</li></ul></div></div></section><section name="6725" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="f621" id="f621" class="graf graf--p graf--leading">The organizations deploying RAG or agentic systems often don‚Äôt fully understand the security implications themselves, creating opportunities for both beneficial security research and real-world exploitation. As these systems move from research prototypes to production deployments, understanding their architecture-specific vulnerabilities becomes essential.</p><p name="52eb" id="52eb" class="graf graf--p graf-after--p">For offensive security practitioners, these systems represent a new frontier. Traditional web application testing techniques apply, but you also need to think about semantic attacks, reasoning manipulation, and autonomous system behavior. The attack surface isn‚Äôt just in the code‚Ää‚Äî‚Ääit‚Äôs in the prompts, the retrieved documents, the tool configurations, and the agent coordination protocols.</p><p name="1a79" id="1a79" class="graf graf--p graf-after--p graf--trailing">Choose your path wisely. üêåüíÄ</p></div></div></section><section name="363b" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="696e" id="696e" class="graf graf--p graf--leading graf--trailing"><strong class="markup--strong markup--p-strong">About the Author</strong> <strong class="markup--strong markup--p-strong">Kai Aizen (SnailSploit)</strong> researches and dismantles AI systems as a GenAI Researcher at ActiveFence. He is the creator of the <a href="https://www.google.com/search?q=https://github.com/aatmf" data-href="https://www.google.com/search?q=https://github.com/aatmf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">AATMF framework</strong></a> (under OWASP consideration), a multiple-CVE discoverer, and author of ‚Äú<strong class="markup--strong markup--p-strong">Adversarial Minds</strong>.‚Äù Follow his primary research on LLM vulnerabilities at <a href="https://snailsploit.com" data-href="https://snailsploit.com" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">SnailSploit.com</strong></a>. <em class="markup--em markup--p-em">Disclaimer: Views are Kai‚Äôs own and do not represent any employer or affiliation.</em></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@snailsploit" class="p-author h-card">Kai Aizen | SnailSploit</a> on <a href="https://medium.com/p/555a22cac4df"><time class="dt-published" datetime="2025-10-17T04:28:27.954Z">October 17, 2025</time></a>.</p><p><a href="https://medium.com/@snailsploit/making-sense-of-rag-agentic-ai-and-the-new-attack-surface-555a22cac4df" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on January 10, 2026.</p></footer></article></body></html>